{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega as bibliotecas\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier, SklearnClassifier\n",
    "import csv\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar uma lista de palavras dada uma frase\n",
    "def divide(dados):    \n",
    "    dados_new = []\n",
    "    for palavra in dados:\n",
    "        palavra_filter = [i.lower() for i in palavra.split()]\n",
    "        dados_new.append(palavra_filter)\n",
    "    return dados_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar a lista de palavras e suas frequências\n",
    "def bag_of_words(palavras):\n",
    "    return dict([(palavra, palavras.count(palavra)) for palavra in palavras])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina os classificadores\n",
    "def treina_classificadores():\n",
    "    posdados = []\n",
    "    with open('train_EPTC_POA_v3nbal_1.data', 'rt', encoding='utf-8') as myfile:    \n",
    "        reader = csv.reader(myfile, delimiter=',')\n",
    "        for val in reader:\n",
    "            posdados.append(str(val[0]))               \n",
    "    negdados = []\n",
    "    with open('train_EPTC_POA_v3nbal_0.data', 'rt', encoding='utf-8') as myfile:    \n",
    "        reader = csv.reader(myfile, delimiter=',')\n",
    "        for val in reader:\n",
    "            negdados.append(val[0])                   \n",
    "    neudados = []\n",
    "    with open('train_EPTC_POA_v3nbal_2.data', 'rt', encoding='utf-8') as myfile:    \n",
    "        reader = csv.reader(myfile, delimiter=',')\n",
    "        for val in reader:\n",
    "            neudados.append(val[0])                         \n",
    "    negfeats = [(bag_of_words(f), 'neg') for f in divide(negdados)]\n",
    "    posfeats = [(bag_of_words(f), 'pos') for f in divide(posdados)]\n",
    "    neufeats = [(bag_of_words(f), 'neu') for f in divide(neudados)]\n",
    "    treino = negfeats + posfeats+ neufeats\n",
    "    #'Maximum Entropy'\n",
    "    classificadorME = MaxentClassifier.train(treino, 'GIS', trace=0, encoding=None, labels=None, gaussian_prior_sigma=0, max_iter = 1)\n",
    "    #SVM\n",
    "    classificadorSVM = SklearnClassifier(LinearSVC(), sparse=False)\n",
    "    classificadorSVM.train(treino)\n",
    "    # Naive Bayes\n",
    "    classificadorNB = NaiveBayesClassifier.train(treino)\n",
    "    return ([classificadorME,classificadorSVM,classificadorNB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para retornar a classificação das frases\n",
    "def classifica(sentencas, classificadores):\n",
    "    ret = []                        \n",
    "    for s in sentencas:\n",
    "        c = divide([s])\n",
    "        feats= bag_of_words(c[0])\n",
    "        classificacao = []\n",
    "        classificacao.append(classificadores[1].classify(feats))\n",
    "        classificacao.append(classificadores[2].classify(feats))\n",
    "        classificacao.append(classificadores[0].classify(feats))\n",
    "        ret.append(classificacao)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina os classificadores\n",
    "classificadores = treina_classificadores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fluxo muito congestionado.', 'Não use o celular ao volante, 80% da sua atenção é desviada.']\n"
     ]
    }
   ],
   "source": [
    "# Define as sentenças\n",
    "sentences = ['Fluxo muito congestionado.', \\\n",
    "            'Não use o celular ao volante, 80% da sua atenção é desviada.']\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['neg', 'neu', 'neg'], ['neu', 'neu', 'neu']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza a classificação\n",
    "classifica(sentences, classificadores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
